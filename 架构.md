

### 第一部分：整体架构设计 (High-Level Architecture Design)

#### 1. 设计理念与原则 (Design Philosophy & Principles)

- **核心哲学：异步、状态驱动的微服务 (Asynchronous, State-Driven Microservices)**
    
    - **理由 (Why):** 我们的系统本质上是“有状态的”（面试历史、用户记忆）。通过使用 SSE 将核心交互变为**异步**，我们解耦了“用户输入”和“LLM 处理”这两个时间尺度完全不同的操作，防止了 LLM 的延迟直接转化为糟糕的 UX。同时，我们将“状态”显式地持久化到 PostgreSQL（而不是内存），这使得后端服务可以水平扩展。
        
- **关键架构原则 (Principles):**
    
    - **CQRS (命令查询责任分离):** 虽然我们不一定需要两个独立的数据库，但我们在逻辑上分离了“写”操作（如 `submit_answer`，这是一个**命令**）和“读”操作（如前端通过 SSE 接收问题，这是一个**事件推送**）。
        
    - **领域驱动设计 (DDD):** 我们的新需求（客户记忆系统）清晰地定义了几个界限上下文 (Bounded Contexts)：`UserManagement` (用户与简历)、`InterviewOrchestration` (面试会话与状态机)、`LLMGateway` (Prompt 管理与上下文策略)。
        
    - **单一职责原则 (SRP):** 每个服务（模块）只做一件事。例如，`Real-time Service` 只管理 SSE 连接，它不关心 LLM 如何生成问题。
        

#### 2. 核心数据模型 (Core Data Model)

我们将使用 PostgreSQL。以下是实现“客户记忆系统”和“会话管理”所需的核心实体。

1. **`Users`** (客户记忆系统的基础)
    
    JSON
    
    ```
    {
      "user_id": "uuid_pk",
      "email": "string_unique",
      "password_hash": "string", // [新增] 密码哈希，支持身份认证
      "created_at": "timestamp"
      // ... 其他客户信息
    }
    ```
    
2. **`Resumes`** (一个客户可以有多个简历) - **[已更新]**
    
    JSON
    
    ```
    {
      "resume_id": "uuid_pk",
      "user_id": "uuid_fk_users",
      "title": "string", // e.g., "针对前端岗位的简历"
      "content": "text", // 用于存储 .md 内容或从 PDF 提取的文本
      "file_url": "string_nullable", // 用于存储原始文件在对象存储 (如 S3) 中的链接
      "mime_type": "string", // 例如 "application/pdf", "image/png", "text/markdown"
      "ocr_status": "string_enum", // [新增] OCR处理状态: [PENDING, SUCCESS, FAILED]
      "created_at": "timestamp"
    }
    ```
    
3. **`InterviewSessions`** (核心的面试会话状态)
    
    JSON
    
    ```
    {
      "session_id": "uuid_pk",
      "user_id": "uuid_fk_users",
      "resume_id": "uuid_fk_resumes",
      "job_description": "text",
      "company_context_summary": "text", // 来自 P-CORP-SUMMARIZE
      "status": "string_enum", // [CONFIGURING, IN_PROGRESS, COMPLETED, FAILED, TIMEOUT]
      "difficulty": "string",
      "provider": "string_enum", // [新] AI 服务商 (GOOGLE, OPENAI, OLLAMA)
      "model": "string", // [新] AI 模型名称 (e.g., "gemini-2.5-flash", "gpt-4o")
      "total_questions": "integer",
      "current_question_index": "integer", // [新增] 当前问题序号
      "error_count": "integer", // [新增] LLM调用失败次数
      "created_at": "timestamp"
    }
    ```
    
4. **`InterviewMessages`** (存储完整的 Q&A 历史)
    
    JSON
    
    ```
    {
      "message_id": "uuid_pk",
      "session_id": "uuid_fk_sessions",
      "sequence": "integer", // 问题的顺序, e.g., 1, 2, 3
      "role": "string_enum", // [AI, USER]
      "content": "text", // 问题或答案
      "topic_tag": "string_nullable", // 关键：用于主题上下文 e.g., "project_react_ecommerce"
      "context_summary": "text_nullable", // [新增] 上下文摘要，用于长对话
      "created_at": "timestamp"
    }
    ```
    
**`PromptTemplates`** (Prompt 即配置)

JSON

```
{
  "prompt_template_id": "uuid_pk",
  "name": "string_unique", // e.g., "P-QUESTION-GENERATE", "P-FINAL-REPORT"
  "version": "integer",     // 1, 2, 3...
  "template_content": "text", // 包含 {{占位符}} 的完整提示词内容
  "is_active": "boolean", // 标记当前线上激活的版本
  "metadata": "jsonb",      // 可选: 存储默认模型参数 (e.g., {"model": "gpt-4o"})
  "context_window_limit": "integer", // [新增] 上下文窗口限制
  "created_at": "timestamp",
  "updated_at": "timestamp"
}
```

**`SystemLogs`** (新增：系统日志表)

JSON

```
{
  "log_id": "uuid_pk",
  "session_id": "uuid_fk_sessions",
  "user_id": "uuid_fk_users",
  "level": "string_enum", // [INFO, WARN, ERROR, FATAL]
  "message": "text",
  "error_code": "string_nullable", // 错误代码
  "retry_count": "integer", // 重试次数
  "created_at": "timestamp"
}
```

- **关系:**
    
    - `Users` (1) -> (M) `Resumes`
        
    - `Users` (1) -> (M) `InterviewSessions`
        
    - `InterviewSessions` (1) -> (M) `InterviewMessages`
         
    - `PromptTemplates` 表与其他表逻辑上独立，由 `LLM Gateway Service` 专属访问。
         
    - `SystemLogs` 表关联 `Users` 和 `InterviewSessions`，用于监控和调试。

#### 3. 技术选型与理由 (Technology Selection & Rationale)

| **类别**       | **技术**                                  | **理由**                                                         |
| ------------ | --------------------------------------- | -------------------------------------------------------------- |
| **前端**       | React (SPA)                             | (用户偏好) 生态系统成熟，适合构建交互复杂的 SPA。                                   |
| **AI 服务**    | **Google Gemini (默认), OpenAI, Ollama**  | (新需求) 提供灵活的 AI 模型选择，以适应不同成本、性能和隐私需求。                       |
| **后端语言/框架**  | Node.js + Fastify/Express               | (用户偏好) Node.js 的异步 I/O 模型与 SSE 和 LLM I/O 完美契合；Fastify 性能高且开销低。 |
| **数据库**      | **PostgreSQL (AWS RDS)**                | (我们的决策) 强大的关系型能力，支持 JSONB，完美契合“客户记忆系统”的持久化需求。                  |
| **实时通信**     | **Server-Sent Events (SSE)**            | (我们的决策) 轻量级、单向推送，比 WebSocket 更简单，非常适合“AI 推送问题”的场景。             |
| **缓存 (可选)**  | Redis                                   | 用于缓存 `P-CORP-SUMMARIZE` 的结果（公司信息不常变），或管理 SSE 连接状态。             |
| **部署(暂不考虑)** | AWS (Fargate/Beanstalk) + S3/CloudFront | (用户偏好) Fargate 提供了无服务器的容器伸缩能力，与我们“可水平扩展”的后端设计一致。               |

#### 4. 逻辑模块划分 (Logical Module Breakdown)

我们将后端拆分为以下几个核心服务（模块）：

1. **User & Memory Service:**
    
    - **职责:** (新) 管理 `Users` 和 `Resumes` 表的 CURD。负责用户身份验证和简历库。**[更新]** 需要处理文件上传，并与对象存储（如S3）交互。
        
2. **Interview Orchestration Service:**
    
    - **职责:** 核心“大脑”。处理 `POST /start`，管理 `InterviewSessions` 的状态机（例如：从 `IN_PROGRESS` 到 `COMPLETED`），存储用户选择的 AI Provider 和 Model，并协调其他服务。
        
3. **LLM Gateway Service:**
    
    - **职责:** **(更新)** 作为一个核心的**抽象层 (Abstraction Layer)**，统一处理对不同 LLM API (Google, OpenAI, Ollama) 的调用。这是一个**高复杂度模块**，需要实现：
        - **API 格式适配:** Google Gemini 使用不同的请求/响应格式，OpenAI 遵循 ChatCompletion 格式，Ollama 使用本地 API 格式
        - **流式响应统一:** 三个服务商的 SSE/流式协议不同，需要统一为内部标准格式
        - **错误码映射:** 将不同服务商的错误码映射为统一的内部错误类型
        - **重试策略:** 实现指数退避重试机制，针对 5xx 错误进行自动重试
        - **认证管理:** 动态选择 API Key、Base URL 或本地连接
        - **上下文窗口管理:** 根据不同模型的上下文限制自动进行内容截断或摘要
    - 它负责从 `PromptTemplates` 数据库表中动态获取、缓存和填充 Prompt，并实现“主题范围上下文”策略。
        
4. **Real-time Service (SSE):**
    
    - **职责:** 管理所有活跃的 SSE 连接。**采用 Redis Pub/Sub 作为主要的异步通信机制**，让 `Orchestration Service` 可以向特定 `session_id` 推送消息。
    - **架构决策说明:** 选择 Redis Pub/Sub 而不是 HTTP 调用，因为：
        - **解耦性:** Pub/Sub 提供了服务间的完全解耦，Orchestration Service 不需要知道 Real-time Service 的具体位置
        - **可扩展性:** 支持水平扩展多个 Real-time Service 实例
        - **性能:** Redis 的发布/订阅模式具有极低的延迟
        - **可靠性:** Redis 提供了消息的持久化和重试机制
        
5. **Company Research Service:**
    
    - **职责:** 封装 Google Search API，为 `Orchestration Service` 提供公司背景信息。
        

---

### 第二部分：迭代开发蓝图 (Iterative Development Blueprint)

#### 1. 开发顺序与依赖关系

**基石 (Must be built first):** `Database Schema` (包含 `Users`, `Resumes`, `InterviewSessions`, `InterviewMessages` **和 `PromptTemplates` 表**)

```
1. 数据库 Schema (所有 5 个核心表)
    |
    +---> 1a. User & Memory Service (Users, Resumes API)
    |
    v
2. Interview Orchestration Service (Core Logic)
    |
    +---> 3. LLM Gateway Service (从 DB 读取 Prompt 并填充)
    |
    +---> 4. Company Research Service (Google API)
    |
    v
3. Real-time Service (SSE) (Async Q&A)
    |
    v
4. Final Report Generation (LLM Call #4)
```

#### 2. 分模块迭代路径 (Module-by-Module Iteration Path)

**(模块 1: `User & Memory Service` (及基础 DB))**

- **目标 (Goal):** **(更新)** 建立 PostgreSQL 数据库，**创建所有 5 个核心表的 Schema (包括 `PromptTemplates`)**。提供 API 来管理用户及其简历。为 `PromptTemplates` 表手动插入 v1 版本的提示词。
    
- **关键接口/数据结构 (Key Interfaces / Data Structures):** (无新增)
    
- **核心验收标准 (Core Acceptance Criteria):**
    
    - **(新增一个标准)**
        
    - **Given:** 数据库已迁移。
        
    - **When:** 我使用 SQL 客户端查询 `PromptTemplates` 表。
        
    - **Then:** 我能看到至少一条 `name` 为 "P-ROLE-VERIFY" 且 `is_active = true` 的记录。
        

**(模块 2: `Interview Orchestration Service` - 启动阶段)**

- **目标 (Goal):** 实现面试的“启动”和“配置”阶段。这包括创建会话、(可选)调用公司研究、(可选)调用 `P-ROLE-VERIFY`。**此阶段尚不涉及 SSE。**
    
- **关键接口/数据结构 (Key Interfaces / Data Structures):**
    
    - `POST /api/v1/interview/start`
        
    - **Request Body:** `{ "user_id": "...", "resume_id": "...", "job_description": "...", "company_name": "..." }`
        
    - **Success Response (Sync):** `{ "session_id": "...", "role_confirmation_text": "..." }` (返回会话 ID 和需要确认的角色描述)
        
    - **Data:** `InterviewSessions` 表。
        
- **核心验收标准 (Core Acceptance Criteria):**
    
    - **Given:** 我有一个 `userId` 和 `resumeId` (来自模块 1)。
        
    - **When:** 我调用 `POST /api/v1/interview/start` 并提供了 `company_name`。
        
    - **Then:** 数据库中应创建一条新的 `InterviewSessions` 记录，并且 `company_context_summary` 字段应被（模拟的）公司研究结果填充。
        

**(模块 3: `Real-time Service (SSE)` & `LLM Gateway` (Q&A 循环))**

- **目标 (Goal):** **(更新)** 实现核心的异步问答循环。`LLM Gateway` 必须从数据库（通过缓存）拉取 `P-QUESTION-GENERATE` 模板，而不是硬编码。
    
- **关键接口/数据结构 (Key Interfaces / Data Structures):** (无新增)
    
- **核心验收标准 (Core Acceptance Criteria):**
    
    - **(新增一个标准)**
        
    - **Given:** 我在 `PromptTemplates` 表中修改了 "P-QUESTION-GENERATE" (v1) 的文本，加入 "TEST_PROMPT" 字样，并清除了 `LLM Gateway` 的缓存。
        
    - **When:** 我作为新用户开始一场面试，并连接到 SSE 端点。
        
    - **Then:** 我收到的第一个问题中必须包含 "TEST_PROMPT" 字样。

---

### 第三部分：集成、部署与运维 (Integration, Deployment & Operations)

#### 1. 最终集成策略 (Final Integration Strategy)

集成的关键在于 `InterviewOrchestration Service` (大脑) 如何通过 `sessionId` 协调所有其他服务。

1. **前端集成:** 前端 UI 必须围绕 `sessionId` 构建。`start` 之后的所有 API 调用都必须携带 `sessionId`。UI 必须正确处理 SSE 的生命周期（连接、接收消息、断线重连）。
    
2. **后端集成:** 核心测试点是 `submit_answer` 的异步流程。我们将使用端到端 (E2E) 测试：
    
    - (Setup) 调用 `POST /start` 获取 `sessionId`。
        
    - (Act 1) 模拟客户端 A 连接到 SSE 端点。
        
    - (Assert 1) 验证客户端 A 收到第一个问题。
        
    - (Act 2) 模拟客户端 B 调用 `POST /submit_answer`。
        
    - (Assert 2) 验证客户端 B 收到 `202`。
        
    - (Assert 3) 验证 `InterviewMessages` 数据库表已更新。
        
    - (Assert 4) 验证客户端 A 在（模拟的）LLM 延迟后收到了第二个问题。
        

#### 2. 部署与运维建议 (Deployment & Ops Recommendations)

- **日志记录 (Logging):**
    
    - 使用结构化日志 (JSON 格式)。
        
    - **关键日志点:** 必须记录所有 LLM 调用的 `session_id`、`prompt_token_count` 和 `response_token_count`。这对于调试“主题上下文”策略和监控成本至关重要。所有日志聚合到 AWS CloudWatch。
        
	- **Prompt 版本跟踪:** 所有 LLM 调用的结构化日志中，**必须**包含 `prompt_template_id` 和 `prompt_version` 字段。这对于调试 Prompt 变更带来的 AI 行为变化至关重要。
	    
- **监控告警 (Monitoring):**
    
    - **API 延迟:** `POST /submit_answer` 的 P99 延迟必须 < 500ms (因为它现在是异步的)。
        
    - **SSE 连接:** 监控活跃的 SSE 连接总数（防止连接泄漏）。
        
    - **LLM 错误率:** `LLM Gateway Service` 必须监控来自 LLM API 的 `4xx/5xx` 错误率（例如 Token 超限、API Key 失效），并设置告警。
        
    - **数据库:** 监控 RDS 的 CPU、内存和连接数。
